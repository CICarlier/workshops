{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script downloads AIS data for later analysis.\n",
    "\n",
    "AIS is a system for tracking ships:\n",
    "\n",
    "  https://en.m.wikipedia.org/wiki/Automatic_identification_system\n",
    "\n",
    "AIS data for ships travelling near the US coastline are available\n",
    "from the US government from this site:\n",
    "\n",
    "  https://marinecadastre.gov/ais/\n",
    "\n",
    "There is a separate data file for each year/month/zone, where 'zone'\n",
    "is a geographical zone numbered from 1 to 20.  A map of the zones is\n",
    "here:\n",
    "\n",
    "  https://marinecadastre.gov/AIS/AIS%20Documents/UTMZoneMap2014.png\n",
    "\n",
    "The data files have URL's with the following format:\n",
    "\n",
    "  https://coast.noaa.gov/htdata/CMSP/AISDataHandler/2017/AIS_2017_01_Zone01.zip\n",
    "\n",
    "To run this script, use the following line in a julia session:\n",
    "\n",
    "~~~\n",
    "include(\"get_ais_data.jl\")\n",
    "~~~\n",
    "\n",
    "You may get a LoadError if you are missing some packages.  Follow the\n",
    "commands on the screen for using Pkg.add to resolve this.\n",
    "\n",
    "Before using this script, you should set the data_dir variable below\n",
    "to point to a directory that you can write to.  Also, you can modify\n",
    "the year, month, and zone ranges below to customize how much data\n",
    "are obtained.\u0013\n",
    "\n",
    "This script uses the `wget` and `unzip` programs, which must be\n",
    "executable from your shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Printf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The download directory.  This must be writeable by you and have enough\n",
    "# space to store the files.  You can delete the zip directory within\n",
    "# data_dir after running this script.\n",
    "data_dir = \"/nfs/kshedden/AIS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the base url for all data files\n",
    "base_url = \"https://coast.noaa.gov/htdata/CMSP/AISDataHandler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The subdirectory of data_dir/raw that will contain the data files\n",
    "# after the script completes running.\n",
    "ais_dir = \"AIS_ASCII_by_UTM_Month\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for storing the raw zip files and the extracted\n",
    "# csv files.\n",
    "mkpath(\"$data_dir/zip\")\n",
    "mkpath(\"$data_dir/raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a collection of AIS data archive files in InfoZip format,\n",
    "# extract the csv files from them, and compress them using gzip.\n",
    "function ais_download()\n",
    "\n",
    "    # Process this range of years\n",
    "    for year in 2016:2016\n",
    "\n",
    "        # Process this range of months\n",
    "        for month in 1:1\n",
    "\n",
    "            # Process this range of zones\n",
    "            for zone in 10:10\n",
    "\n",
    "                # Form the url as a string\n",
    "                b = @sprintf(\"AIS_%4d_%02d_Zone%02d.zip\", year, month, zone)\n",
    "                u = @sprintf(\"%s/%4d/%s\", base_url, year, b)\n",
    "\n",
    "                # Download the data from the url.  The file is a zip file\n",
    "                # (i.e. an InfoZip archive).\n",
    "                cmd = `wget $u -O $data_dir/zip/$b`\n",
    "                run(cmd)\n",
    "\n",
    "                # Unzip the file.  Each zip archive should contain exactly\n",
    "                # one csv file, which is extracted to the 'raw' directory\n",
    "                # of data_dir.\n",
    "                cmd = `unzip -o $data_dir/zip/$b -d $data_dir/raw`\n",
    "                run(cmd)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Gzip compress all the csv files\n",
    "    for (root, dirs, files) in walkdir(\"$data_dir/raw\")\n",
    "        for f in files\n",
    "            if splitext(f)[2] == \".csv\"\n",
    "                p = joinpath(root, f)\n",
    "                cmd = `gzip -f $p`\n",
    "                run(cmd)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Some of the years are stored in a directory named YYYY_v2,\n",
    "    # e.g. 2017_v2.  Create a symlink with only the year to make\n",
    "    # it easier to access the files by year.\n",
    "    for f in readdir(\"$data_dir/raw/$ais_dir\")\n",
    "        if occursin(\"_\", f)\n",
    "            v = split(f, \"_\")\n",
    "            year = v[1]\n",
    "            if !ispath(\"$data_dir/raw/$ais_dir/$year\")\n",
    "                symlink(\"$data_dir/raw/$ais_dir/$f\", \"$data_dir/raw/$ais_dir/$year\")\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to download the data\n",
    "ais_download()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "julia",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
